# Install package
install.packages("tidyverse")
install.packages("caret")
install.packages("gridExtra")

# Load package 
library("tidyverse")
library("caret")
library("gridExtra")


# Read csv file 
df <- read_csv("customer_churn_data.csv")

# Data preprocessing
View(df)
glimpse(df)
head(df)
tail(df)
names(df)
summary(df)

## Check columns name
names(df)

## Change column names to lowercase and Check missing value
names(df) <- tolower(names(df))
sum(is.na(df))


df%>%
  select(internetservice) %>%
  group_by(internetservice) %>%
  count()

## create a new data frame without the customerid and techsupport column and Removes all rows containing "None" values 

df <- df %>%
  select(-1, -9) %>%
  filter(internetservice != "None")

df%>%
  select(internetservice) %>%
  group_by(internetservice) %>%
  count()

## Convert character data type to factor data type

df <- df %>%
  mutate_if(is.character, as.factor)
glimpse(df)

# Exploration data analysis

## Create the individual plots

p1 <- ggplot(df, aes(gender, fill = churn)) + 
  geom_bar(position = position_dodge()) + 
  theme_minimal() +
  ggtitle("Gender by Churn") +
  theme(plot.title = element_text(hjust = 0.5))
  
p2 <- ggplot(df, aes(contracttype, fill = churn)) + 
  geom_bar(position = position_dodge()) + 
  theme_minimal() +
  ggtitle("Contract Type by Churn") +
  theme(plot.title = element_text(hjust = 0.5))
  
p3 <- ggplot(df, aes(internetservice, fill = churn)) + 
  geom_bar(position = position_dodge()) + 
  theme_minimal() +
  ggtitle("Internet Service by Churn") +
  theme(plot.title = element_text(hjust = 0.5))
  
p4 <- ggplot(df, aes(churn, monthlycharges, fill = churn)) +
  geom_boxplot() + 
  theme_minimal() + 
  ggtitle("Monthly Charges vs. Churn") +
  theme(plot.title = element_text(hjust = 0.5))

## Arrange the plots in a grid

grid.arrange(p1, p2, p3, p4, ncol = 2)
  


  
  
# Built Basic Machine Learning Model
# Split data 
set.seed(42)
n <- nrow(df)
id <- sample(1:n, size = 0.8*n, replace = FALSE)
train_data <- df[id, ] 
test_data <- df[-id, ]

# Logistic Regression with K-Fold CV 
set.seed(42)
ctrl <- trainControl(method = "cv",
                     number = 5)
logit_model <- train(churn ~ .,
                     data = train_data,
                     method = "glm",
                     trControl = ctrl)

# test model 

p_logit <- predict(logit_model, newdata = test_data)

# confusion matrix

confusionMatrix(p_logit, test_data$churn, positive = "Yes",mode = "prec_recall")

accuracy_logit <- round(mean( p_logit == test_data$churn), 4)


print(paste0("Logistic Regression Accuracy : ", accuracy_logit*100))

------------------------------------------------------------------------------

# Train model decision tree with Repeated K-Fold CV 
set.seed(42)
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     number = 5,
                     verboseIter = TRUE)
tree_model <- train(churn ~ .,
                     data = train_data,
                     method = "rpart",
                     trControl = ctrl)

# Test model 

p_tree <- predict(tree_model, newdata = test_data)

# Confusion matrix

confusionMatrix(p_tree, test_data$churn, positive = "Yes",mode = "prec_recall")

accuracy_tree <- round(mean( p_tree == test_data$churn),4)

print(paste0("Decision Tree Accuracy : ", accuracy_tree*100))

------------------------------------------------------------------------------

# Random forest with Repeated K-Fold CV

set.seed(42)
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     number = 5,
                     verboseIter = TRUE)
rf_model <- train(churn ~ .,
                    data = train_data,
                    method = "rf",
                    trControl = ctrl)

# Test model 

p_rf <- predict(rf_model, newdata = test_data)

# Confusion matrix

confusionMatrix(p_rf, test_data$churn, positive = "Yes",mode = "prec_recall")

accuracy_rf <- round(mean( p_rf == test_data$churn), 4)

print(paste0("Random Forest Accuracy : ", accuracy_rf*100))


# Conclusion Accuracy

## Train Model Accuracy

cat("Logistic Regression Train Model Accuracy : ",round(logit_model$results$Accuracy, 4)*100,
    "\nDecision Tree Train Model Accurary : ", round(max(tree_model$results$Accuracy), 4)*100,
    "\nRandom Forest Train Model Accuracy : ", round(max(rf_model$results$Accuracy), 4)*100)

## Test Model Accuracy

cat("Logistic Regression Test Model Accuracy : ", accuracy_logit*100,
    "\nDecision Tree Test Model Accurary : ", accuracy_tree*100,
    "\nRandom Forest Test Model Accuracy : ", accuracy_rf*100)



